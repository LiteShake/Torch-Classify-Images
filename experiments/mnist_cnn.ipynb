{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    './data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    './data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7* 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()# .to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_mnist_images', img_grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images.to(device))\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    print(labels.shape)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        # matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3512685298919678\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs# .to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        labels = labels# .to(device)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "    print(loss.item())\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
